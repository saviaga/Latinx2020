{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Public Groups/Pages classify groups by State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(row):\n",
    "    name =  row.lower().split('/')\n",
    "    if  row.lower().startswith('https') or  row.lower().startswith('http'):       \n",
    "        return name[3]\n",
    "    elif row.lower().startswith('www'):\n",
    "        return name[1] \n",
    "    elif row.lower().startswith('facebook'):\n",
    "        return name[1]\n",
    "    else:\n",
    "        print(\"Not found\", row)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reads  Info\n",
    "Reads the information from all the posts from the studied period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cscwDocs/parties/FBPagesGroupsData/FBPagesGroupsCities/LatinosEstadosPagesAug182020-Nov032020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-51284c59c7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cscwDocs/parties/FBPagesGroupsData/FBPagesGroupsCities/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mposts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"LatinosEstadosPagesAug182020-Nov032020.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#We rename the colum Page Name to be able to concat with Group Posts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mposts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Page Name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Group Name'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mposts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"LatinosEstadosGroups-Aug182020-Aug252020.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cscwDocs/parties/FBPagesGroupsData/FBPagesGroupsCities/LatinosEstadosPagesAug182020-Nov032020.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"cscwDocs/parties/FBPagesGroupsData/FBPagesGroupsCities/\"\n",
    "posts1 = pd.read_csv(path+\"LatinosEstadosPagesAug182020-Nov032020.csv\")\n",
    "#We rename the colum Page Name to be able to concat with Group Posts\n",
    "posts1.rename(columns={'Page Name':'Group Name'}, inplace=True)\n",
    "posts2 = pd.read_csv(path+\"LatinosEstadosGroups-Aug182020-Aug252020.csv\")\n",
    "posts3 = pd.read_csv(path+\"LatinosEstadosGroups-Aug262020-Aug312020.csv\")\n",
    "posts4 = pd.read_csv(path+\"LatinosEstadosGroups-Sep012020-Sep042020.csv\")\n",
    "posts5 = pd.read_csv(path+\"LatinosEstadosGroups-Sep052020-Sep082020.csv\")\n",
    "posts6 = pd.read_csv(path+\"LatinosEstadosGroups-Sep092020-Sep122020.csv\")\n",
    "posts7 = pd.read_csv(path+\"LatinosEstadosGroups-Sep132020-Sep162020.csv\")\n",
    "posts8 = pd.read_csv(path+\"LatinosEstadosGroups-Sep172020-Sep202020.csv\")\n",
    "posts9 = pd.read_csv(path+\"LatinosEstadosGroups-Sep212020-Sep242020.csv\")\n",
    "posts10 = pd.read_csv(path+\"LatinosEstadosGroups-Sep252020-Sep282020.csv\")\n",
    "posts11 = pd.read_csv(path+\"LatinosEstadosGroups-Sep292020-Oct022020.csv\")\n",
    "posts12 = pd.read_csv(path+\"LatinosEstadosGroups-Oct032020-Oct062020.csv\")\n",
    "posts13 = pd.read_csv(path+\"LatinosEstadosGroups-Oct072020-Oct102020.csv\")\n",
    "posts14 = pd.read_csv(path+\"LatinosEstadosGroups-Oct112020-Oct142020.csv\")\n",
    "posts15 = pd.read_csv(path+\"LatinosEstadosGroups-Oct152020-Oct172020.csv\")\n",
    "posts16 = pd.read_csv(path+\"LatinosEstadosGroups-Oct182020--Oct212020.csv\")\n",
    "posts17 = pd.read_csv(path+\"LatinosEstadosGroups-Oct222020-Oct252020.csv\")\n",
    "posts18 = pd.read_csv(path+\"LatinosEstadosGroups-Oct262020-Oct292020.csv\")\n",
    "posts19 = pd.read_csv(path+\"LatinosEstadosGroups-October302020-Nov032020.csv\")\n",
    "posts = pd.concat([posts1,posts2,posts3,posts4,posts5,posts6,posts7,posts8,posts9,\n",
    "                   posts10,posts11,posts12,posts13,posts14,posts15,posts16,posts17,posts18,posts19])\n",
    "posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 400)\n",
    "posts['URL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Filter the most relevant columns\n",
    "### Add column to concat Message, Description, Link Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_message = posts['Message'].fillna('') + (' ' + posts['Description']).fillna('')+ (' ' + posts['Link Text']).fillna('') + (' ' + posts['Link']).fillna('')\n",
    "posts['MessageDescr'] = concat_message\n",
    "\n",
    "concat_just_message = posts['Message'].fillna('') + (' ' + posts['Description']).fillna('')+ (' ' + posts['Link Text']).fillna('')\n",
    "posts['MessageOnly'] = concat_just_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posts[posts['Link Text'].str.lower().str.contains(\"í\", na = False)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import re\n",
    "\n",
    "text = u'This is a smiley face \\U0001f602'\n",
    "print(text) # with emoji\n",
    "\n",
    "def deEmojify(text):\n",
    "    \n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                          \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    \n",
    "    \n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "print(deEmojify(text))\n",
    "\n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posts['Group Name']=posts['Group Name'].apply(deEmojify)\n",
    "posts['Group Name']=posts['Group Name'].apply(lambda i: i.replace('\"', ''))\n",
    "posts['Group Name']=posts['Group Name'].apply(lambda i: i.replace(',', ''))\n",
    "posts['Facebook Id'] = posts['Facebook Id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read FB Group Names & State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fb_groups = pd.read_csv(\"cscwDocs/parties/FBGroupsPolitical_cities.csv\")\n",
    "fb_groups['Facebook Id'] = fb_groups['Page or Account URL'].str.strip(\"https://www.facebook.com/groups/\")\n",
    "fb_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. US states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = pd.DataFrame({'State':['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','District of Columbia','Florida',\n",
    "             'Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts',\n",
    "             'Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico',\n",
    "             'New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina',\n",
    "             'South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Count posts in general by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "data_frames = [fb_groups, posts]\n",
    "fb_groups['Facebook Id'] = fb_groups['Facebook Id'].astype(int)\n",
    "df_posts_state  = reduce(lambda  left,right: pd.merge(left,right,on=['Facebook Id'],\n",
    "                                            how='outer'), data_frames)\n",
    "df_count = df_posts_state.groupby(['State']).agg({'Facebook Id':'count'}).reset_index() \n",
    "\n",
    "df_count.columns = ['State','Posts_Counts']\n",
    "df_count.sort_values(by=['State'], ascending=True,inplace=True)\n",
    "df_count.fillna(0, inplace=True)\n",
    "df_count['Posts_Counts'] = df_count['Posts_Counts'].astype(int)\n",
    "df_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [df_count, us_states]\n",
    "missing_states  = reduce(lambda  left,right: pd.merge(left,right,on=['State'],\n",
    "                                            how='outer'), data_frames)\n",
    "missing_states.fillna(0, inplace=True)\n",
    "missing_states['Posts_Counts'] = missing_states['Posts_Counts'].astype(int)\n",
    "missing_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.to_csv('cscwDocs/FB_groups_States/FB_groups_posts_by_state2.csv',index=False,na_rep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_state.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Which groups are publishing the majority of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = posts.groupby(['Group Name'])\n",
    "final_groups = group.agg({'Facebook Id':'count'}).sort_values(by='Facebook Id',ascending=False)\n",
    "final_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_groups.to_csv(\"cscwDocs/FB_groups_States/Posts_Per_group2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filter posts per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topics\n",
    "economy = 'economy|economía|economia|welfare|taxes|unemployment|employment|job|minimum-wage|union|poverty|poor|homeless|stock|gdp'\n",
    "health_care = 'health care|salud|medico|médico|salud|doctor|medicaid|medicare|planned parenthood|insurance|injury|disability'\n",
    "coronavirus = 'coronavirus|covid|pandemia|vacuna|tos|fiebre|enfermo|pandemic|vaccine|fever|sick'\n",
    "crime = 'crime|crimen|pandilla|violento|vandalism|violence|crime|robbery|theft|gang'\n",
    "supreme_court = 'supreme court|suprema corte|juez|corte suprema|ruth bader ginsberg'\n",
    "climate_change = 'climate change|cambio climático|environment|recycle|pollution|litter|nature|climate change|global warming ",
    "'\n",
    "immigration = 'immigration|migration|inmigración|migración|immigracion|indocumentado|frontera|pared|ice|border'\n",
    "immigration2 = 'immigration|migration|inmigración|migración|immigracion|indocumentado|frontera|muro|ice|border|frontera'\n",
    "gun_policy = 'gun policy|gun policies|política de armas|guns rights|NRA|armas|arma|pistola|política de armas|armas|gun violence|shooting|2nd amendment|second amendment|concealed carry'\n",
    "foreign_policy ='foreign policy|política exterior|foreign policies|china|russia|united kingdom|england|mexico|canada|trade|embargo|ambassador|consulate|middle east|prime minister|war'\n",
    "abortion = 'aborto|abortion|aborto|feto|embarazada|planned parenthood|abortion|fetus|trimester|miscarriage|pregnancy'\n",
    "racism = 'racial inequality|etnic inqueality|racism|racismo|inequidad racial|inequidad étnica|crimen de odio|igualdad de raza y étnica|discriminación|black|hate crime|racism|desigualdad|blm|all lives matter'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "path = 'cscwDocs/FB_groups_States/Topics/'\n",
    "prefix = 'FB_groups_States_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_economy = df_posts_state.copy()\n",
    "posts_economy = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(economy   ,na = False)]\n",
    "print('economy', posts_economy.shape)\n",
    "posts_economy.to_csv(path + prefix + 'economy' + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='health_care'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(health_care ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='coronavirus'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(coronavirus ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='crime'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(crime ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='supreme_court'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(supreme_court ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='climate_change'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(climate_change ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='immigration'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(immigration ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='immigration2'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(immigration2 ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='gun_policy'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(gun_policy ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='foreign_policy'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(foreign_policy ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='abortion'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(abortion ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='racism'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(racism ,na = False)]\n",
    "print(topic, df.shape)\n",
    "df.to_csv(path + prefix + topic + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='immigration2'\n",
    "df = df_posts_state.copy()\n",
    "df = df_posts_state[df_posts_state['MessageDescr'].str.lower().str.contains(immigration2 ,na = False)]\n",
    "print(topic, df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(round(df.shape[0] * 0.10))\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic, df.shape, sample.shape)\n",
    "name='immigration_random'\n",
    "sample.to_csv(path + prefix + name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Latinx2020env",
   "language": "python",
   "name": "latinx2020env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
